{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-07T02:12:33.234374Z",
     "start_time": "2024-05-07T02:12:33.227639Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T02:12:33.283172Z",
     "start_time": "2024-05-07T02:12:33.243375Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('data/cleaned_house_sales.csv')",
   "id": "5373191e815e7aca",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T02:13:27.631507Z",
     "start_time": "2024-05-07T02:13:26.331770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['city', 'house_type'], drop_first=True)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_encoded['area'] = imputer.fit_transform(df_encoded[['area']])\n",
    "df_encoded['months_listed'] = imputer.fit_transform(df_encoded[['months_listed']])\n",
    "df_encoded['bedrooms'] = imputer.fit_transform(df_encoded[['bedrooms']])\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_encoded[['area', 'months_listed', 'bedrooms']]),\n",
    "                         columns=['area', 'months_listed', 'bedrooms'])\n",
    "\n",
    "# Combine encoded and scaled features with original dataframe\n",
    "df_preprocessed = pd.concat([df_encoded.drop(['area', 'months_listed', 'bedrooms'], axis=1), df_scaled], axis=1)\n",
    "\n",
    "# Display the preprocessed dataframe\n",
    "print(df_preprocessed.head())"
   ],
   "id": "8f7b22c3a841ab1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   house_id  sale_price   sale_date  city_Riverford  city_Silvertown  \\\n",
      "0   1217792       55943  2021-09-12           False             True   \n",
      "1   1900913      384677  2021-01-17           False             True   \n",
      "2   1174927      281707  2021-11-10            True            False   \n",
      "3   1773666      373251  2020-04-13           False             True   \n",
      "4   1258487      328885  2020-09-24           False             True   \n",
      "\n",
      "   city_Teasdale  city_Unknown  house_type_Semi-detached  house_type_Terraced  \\\n",
      "0          False         False                      True                False   \n",
      "1          False         False                     False                False   \n",
      "2          False         False                     False                False   \n",
      "3          False         False                     False                False   \n",
      "4          False         False                     False                False   \n",
      "\n",
      "       area  months_listed  bedrooms  \n",
      "0 -1.673053      -0.259409 -1.428248  \n",
      "1  1.004391       0.206161  0.695015  \n",
      "2  1.303635       0.516541  1.402769  \n",
      "3  1.207083       0.102701  1.402769  \n",
      "4  0.855796       1.447681  0.695015  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Regression",
   "id": "585fc27596b54cfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T02:40:23.507122Z",
     "start_time": "2024-05-07T02:40:23.201919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Convert 'sale_date' to datetime format\n",
    "df_preprocessed['sale_date'] = pd.to_datetime(df_preprocessed['sale_date'])\n",
    "\n",
    "# Extract year, month, and day features from 'sale_date'\n",
    "df_preprocessed['sale_year'] = df_preprocessed['sale_date'].dt.year\n",
    "df_preprocessed['sale_month'] = df_preprocessed['sale_date'].dt.month\n",
    "df_preprocessed['sale_day'] = df_preprocessed['sale_date'].dt.day\n",
    "\n",
    "# Drop the original 'sale_date' column\n",
    "df_preprocessed.drop(columns=['sale_date'], inplace=True)\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocessed.drop(columns=['sale_price']),\n",
    "                                                    df_preprocessed['sale_price'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),   # Standardize numerical features\n",
    "    ('model', LinearRegression())   # Linear regression model\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "mean_mse = -cv_scores.mean()  # Take the negative of mean squared error\n",
    "\n",
    "print('Mean squared error (Cross-Validation):', mean_mse)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, predictions)\n",
    "print('Mean squared error (Test Set):', mse_test)"
   ],
   "id": "81765267f962d3a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (Cross-Validation): 521901059.8037545\n",
      "Mean squared error (Test Set): 496856809.7794371\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest Regressor",
   "id": "b4030abb6ac1e68d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T03:11:59.436320Z",
     "start_time": "2024-05-07T02:46:03.120436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),   # Standardize numerical features\n",
    "    ('model', RandomForestRegressor())   # Random forest regression model\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],           # Number of trees in the forest\n",
    "    'model__max_depth': [10, 20, 30, None],           # Maximum depth of the trees\n",
    "    'model__min_samples_split': [2, 5, 10],           # Minimum number of samples required to split a node\n",
    "    'model__min_samples_leaf': [1, 2, 4],             # Minimum number of samples required at each leaf node\n",
    "    'model__bootstrap': [True, False]                 # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its performance\n",
    "best_model = grid_search.best_estimator_\n",
    "best_mse = -grid_search.best_score_\n",
    "\n",
    "print('Best Parameters:', grid_search.best_params_)\n",
    "print('Mean squared error (Cross-Validation):', best_mse)"
   ],
   "id": "a990137692aea573",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__bootstrap': True, 'model__max_depth': 20, 'model__min_samples_leaf': 2, 'model__min_samples_split': 10, 'model__n_estimators': 300}\n",
      "Mean squared error (Cross-Validation): 245753725.7881964\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradient Boosting Regressor",
   "id": "1981f132ca00c5e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T03:51:32.017011Z",
     "start_time": "2024-05-07T03:11:59.458947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),   # Standardize numerical features\n",
    "    ('model', GradientBoostingRegressor())   # Gradient boosting regression model\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],           # Number of trees in the forest\n",
    "    'model__max_depth': [10, 20, 30, None],           # Maximum depth of the trees\n",
    "    'model__min_samples_split': [2, 5, 10],           # Minimum number of samples required to split a node\n",
    "    'model__min_samples_leaf': [1, 2, 4],             # Minimum number of samples required at each leaf node\n",
    "    'model__learning_rate': [0.1, 0.01, 0.001]       # Learning rate\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its performance\n",
    "best_model = grid_search.best_estimator_\n",
    "best_mse = -grid_search.best_score_\n",
    "\n",
    "print('Best Parameters:', grid_search.best_params_)\n",
    "print('Mean squared error (Cross-Validation):', best_mse)"
   ],
   "id": "e80eb5bddf0446a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 100}\n",
      "Mean squared error (Cross-Validation): 285956687.158507\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### XGBoost Regressor",
   "id": "747233bb77823a24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T03:55:14.372363Z",
     "start_time": "2024-05-07T03:51:32.020010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),   # Standardize numerical features\n",
    "    ('model', XGBRegressor())   # XGBoost regression model\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],           # Number of trees in the forest\n",
    "    'model__max_depth': [10, 20, 30, None],           # Maximum depth of the trees\n",
    "    'model__learning_rate': [0.1, 0.01, 0.001]       # Learning rate\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its performance\n",
    "best_model = grid_search.best_estimator_\n",
    "best_mse = -grid_search.best_score_\n",
    "\n",
    "print('Best Parameters:', grid_search.best_params_)\n",
    "print('Mean squared error (Cross-Validation):', best_mse)"
   ],
   "id": "a5d50b09b413e103",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__learning_rate': 0.1, 'model__max_depth': None, 'model__n_estimators': 100}\n",
      "Mean squared error (Cross-Validation): 279458378.94457513\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
